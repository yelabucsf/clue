{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import itertools as it\n",
    "import json\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "from functools import reduce\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.verbosity = 4\n",
    "sc.settings.set_figure_params(dpi=80)\n",
    "print(sc.__version__)\n",
    "sc.settings.n_jobs=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '/data/codec/production.run/mrna/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = prefix + 'obs/acg.nk.txt'\n",
    "\n",
    "# with open(path,'w') as file:\n",
    "#     for bc in acg_nk.obs_names:\n",
    "#         file.write(bc + '\\n')\n",
    "        \n",
    "with open(path,'r') as file:\n",
    "    acg_nk_cells = [i.strip() for i in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = prefix + 'pkls/aggr/wells.sng.w_covars.pkl'\n",
    "\n",
    "# with open(path,'wb') as file:\n",
    "#     pkl.dump(wells, file)\n",
    "    \n",
    "with open(path,'rb') as file:\n",
    "    wells = pkl.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Cell Barcodes, Filter\n",
    "\n",
    "I'm adjusting the cell barcodes to make them match their well number, which I also did with the ADTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for well in wells:\n",
    "    wells[well]['adata'].obs_names = [i[:16] + '-%s' % well for i in wells[well]['adata'].obs_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acg_nk = wells[0]['adata'].concatenate(*[wells[i]['adata'] for  i in range(1, 12)])[acg_nk_cells].copy() # I really shouldn't do this, I should go back and run cellranger aggr, but for now just concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acg_nk.var['n_counts'] = acg_nk.X.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Genes, Transform Data\n",
    "\n",
    "Drop genes with very low counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(acg_nk.var['n_counts'].values)\n",
    "plt.grid(False)\n",
    "plt.grid(True, 'both', 'both')\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_per_cell(acg_nk, counts_per_cell_after=1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.log1p(acg_nk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/codec/production.run/adts/pkls/combat/concat.combat.adts.norm.log.pkl'\n",
    "with open(path,'rb') as file:\n",
    "    concat_adts = pkl.load(file)\n",
    "transcripts = acg_nk.var_names\n",
    "proteins = concat_adts['adata'].var_names\n",
    "adts_df = pd.DataFrame(concat_adts['adata'].X, columns=proteins, index=concat_adts['adata'].obs_names)\n",
    "acg_nk.obs = acg_nk.obs.join(adts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highly Variable Genes Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hv_run(adata, flavor='cell_ranger', min_mean=0.0125, min_disp=0.5, max_mean=3, bins=500):    # Extract out highly variable genes, but don't subset just yet\n",
    "    '''\n",
    "    Run highly variable genes and return a new adata object, if provided.\n",
    "    '''\n",
    "    hv_adata = adata.copy() # make a copy because I don't want to change the original just yet\n",
    "    sc.pp.highly_variable_genes(hv_adata, flavor=flavor,inplace=True, \n",
    "                                min_mean=min_mean, \n",
    "                                min_disp=min_disp, \n",
    "                                max_mean=max_mean,\n",
    "                                n_bins=bins)\n",
    "    \n",
    "    means = hv_adata.var['means'].values\n",
    "    means_sorted = np.unique(np.sort(means))\n",
    "    if means_sorted[0] == 0:\n",
    "        mean_shift = means_sorted[1]\n",
    "    elif means_sorted[0] < 0:\n",
    "        mean_shift = means_sorted[1] - 2*means_sorted[0]\n",
    "    else:\n",
    "        mean_shift = 0\n",
    "    \n",
    "    disps = hv_adata.var['dispersions_norm'].values\n",
    "    disps_sorted = np.unique(np.sort(disps))\n",
    "    if disps_sorted[0] == 0:\n",
    "        disp_shift = disps_sorted[1]\n",
    "    elif disps_sorted[0] < 0:\n",
    "        disp_shift = disps_sorted[1] - 2*disps_sorted[0]\n",
    "    else:\n",
    "        disp_shift = 0\n",
    "        \n",
    "    log_means = np.log10(means + mean_shift)\n",
    "    log_disps = np.log10(disps + disp_shift)\n",
    "    \n",
    "    hv_adata.var['log_means'] = log_means\n",
    "    hv_adata.var['log_disps'] = log_disps\n",
    "    \n",
    "    return hv_adata\n",
    "\n",
    "def hv_plot(hv_adata, gate=None, highlight_genes=None, bw='scott'):\n",
    "    '''\n",
    "    Plot the means and normalized dispersions from the adata object provided. Choose to\n",
    "    also plot a gate or highlight certain genes.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    # do what the scanpy function does, plotting normalized dispersions with means as blue dots, \n",
    "    # I don't want to plot in logspace but I don't want to use the log function because then the gates don't work\n",
    "    # if they contain segments with fractional slopes (i.e. non-straight lines). To be robust to these gates, I therefore \n",
    "    # will log10 everything and just plot in linear space\n",
    "    log_means = hv_adata.var['log_means'].values\n",
    "    log_disps = hv_adata.var['log_disps'].values\n",
    "    \n",
    "    fig = plt.figure(figsize=(19, 6))\n",
    "    gs = GridSpec(2, 3, figure=fig)\n",
    "    ax1 = fig.add_subplot(gs[:, 0])\n",
    "    ax2 = fig.add_subplot(gs[:, 1])\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax4 = fig.add_subplot(gs[1, 2])\n",
    "\n",
    "#     ax1.hist2d(log_means, log_disps, bins=bins);\n",
    "    ax1.get_xaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "    ax1.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "    ax1.grid(True, which='both',axis='both', alpha=0.4)\n",
    "    ax1.set_ylabel('Log Dispersions')\n",
    "    ax1.set_xlabel('Log Means')\n",
    "    sns.kdeplot(log_means, log_disps, bw=bw, shade=True, shade_lowest=False, ax=ax1, color='skyblue')\n",
    "\n",
    "    ax2.minorticks_on() # throw on the minor ticks for use with the grid, will help with subsetting\n",
    "    ax2.grid(True,which='both',axis='both') # turn the grid on\n",
    "    ax2.scatter(log_means, log_disps, s=0.1, c='b')\n",
    "    ax2.set_ylabel('Log Dispersions')\n",
    "    ax2.set_xlabel('Log Means')\n",
    "\n",
    "#     ax3.hist(log_means, bins=bins)\n",
    "    ax3.minorticks_on()\n",
    "    ax3.grid(True,which='both',axis='both')\n",
    "    ax3.set_title('Log Means')\n",
    "    sns.kdeplot(log_means, bw=bw, ax=ax3, color='blue')\n",
    "\n",
    "#     ax4.hist(log_disps, bins=bins)\n",
    "    ax3.minorticks_on()\n",
    "    ax3.grid(True,which='both',axis='both')\n",
    "    ax4.set_title('Log Dispersions')\n",
    "    sns.kdeplot(log_disps, bw=bw, ax=ax4, color='blue')\n",
    "\n",
    "    plt.tight_layout();\n",
    "\n",
    "    if type(highlight_genes) != type(None): # do you want to highlight some genes?\n",
    "        mask = [i in highlight_genes for i in hv_adata.var_names] # create a boolean mask of which genes to highlight\n",
    "        highlight_means = log_means[mask] # subset only those means\n",
    "        highlight_disps = log_disps[mask] # subset only those dispersions\n",
    "        ax2.scatter(highlight_means,highlight_disps,s=30, facecolors='none', edgecolors='r'); # plot with a red circle around the blue dot\n",
    "        \n",
    "    if type(gate) != type(None):\n",
    "        # You can draw a gate around the genes you want. There should be a check for using only rectangular gates (or only polygons with right angles). \n",
    "        # I have noted that if you try to draw angled lines in log space using the shapely package, the points_in_poly function does not return the right subset of points within the polygon.\n",
    "        gatepatch = patches.Polygon(gate,linewidth=1,edgecolor='teal',facecolor='turquoise',alpha=0.5) # create a matplotlib patch for the gate to the plot\n",
    "        ax2.add_patch(gatepatch); # add the gate to the plot\n",
    "\n",
    "def hv_genes(hv_adata, gate, adata=None):\n",
    "    '''\n",
    "    Receive boolean for genes in gate or new subsetted adata object, if provided.\n",
    "    '''\n",
    "    # You can subset the genes you want using the gate. Again, there should be a check for using only rectangular gates (or only polygons with right angles). \n",
    "    # I have noted that if you try to draw angled lines in log space using the shapely package, the points_in_poly function does not return the right subset of points within the polygon.\n",
    "    genes = list()\n",
    "    log_means = hv_adata.var['log_means'].values\n",
    "    log_disps = hv_adata.var['log_disps'].values\n",
    "    \n",
    "    pointsmap = map(Point,log_means,log_disps) # make each point a shapely.geometry.Point\n",
    "    \n",
    "    polygon = Polygon(gate) # make your gate a shapely.geometry.Polygon\n",
    "    for i in pointsmap:\n",
    "        genes.append(polygon.contains(i)) # this is the workhorse, determining which points are in the gate\n",
    "    if type(adata) != type(None): # if the adata has been provided, subset it\n",
    "        adata = adata[:,genes].copy()\n",
    "        return adata\n",
    "    else: # if it has not been provided return the boolean array noting which genes will be kept\n",
    "        return genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a \"highly variable adata\" object that has run the highly variable genes extraction function. I generate a separate object because I don't want to necessarily change the original object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_adata = hv_run(acg_nk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_plot(hv_adata, highlight_genes=[i for i in acg_nk.var_names if i.startswith('RP')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrange = (-1.4, 1.2)\n",
    "yrange = (0.65, 1.4)\n",
    "gate = np.array([(xrange[0], yrange[0]), \n",
    "                  (xrange[0], yrange[1]), \n",
    "                  (xrange[1], yrange[1]), \n",
    "                  (xrange[1], yrange[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_plot(hv_adata, gate=gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = hv_genes(hv_adata, gate=gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a new adata object with your genes now subsetted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acg_nk = hv_genes(hv_adata, gate=gate, adata=acg_nk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acg_nk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(10,4))\n",
    "for vals, ax in zip(['percent_mito','n_counts'], np.ravel(ax)):\n",
    "    ax.hist(acg_nk.obs[vals].values,bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.regress_out(acg_nk, ['percent_mito','n_counts'],n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.scale(acg_nk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.combat(acg_nk, key='batch',covariates=['cond','free_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.pca(acg_nk,n_comps=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca_variance_ratio(acg_nk,log=True, n_pcs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(acg_nk,n_neighbors=15,n_pcs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.umap(acg_nk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(acg_nk, resolution=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acg_nk.uns['cond_colors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnk.uns['cond_colors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
    "for color, ax, palette in zip(['cond', 'leiden'], ax, [None, sc.pl.palettes.default_20]):\n",
    "    sc.pl.umap(acg_nk,color=color, ax=ax, show=False, return_fig=False, size=20, palette=palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(5.5,5))\n",
    "ax.set_facecolor('black')\n",
    "sc.pl.umap(acg_nk, color='PDGFD', ax=ax,show=False, return_fig=False, size=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusts = ['1','3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_acg_nk = dict()\n",
    "for clust in clusts:\n",
    "    sub_acg_nk[str(clust)] = acg_nk[acg_nk.obs['leiden'] == str(clust)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(sub_acg_nk['1'], resolution=0.4) # subcluster them using Leiden\n",
    "sc.pl.umap(sub_acg_nk['1'],color='leiden', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(sub_acg_nk['3'], resolution=0.3) # subcluster them using Leiden\n",
    "sc.pl.umap(sub_acg_nk['3'],color='leiden', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def sub_cluster_mapper(adata, sub_adatas):\n",
    "    '''\n",
    "    This takes in the adata object and inserts a new leiden column in the `.obs`. \n",
    "    \n",
    "    This function is really convoluted and there's probably a better, simpler way to do it,\n",
    "    but it should theoretically work for any number of subclusters\n",
    "    '''\n",
    "    # ideally you'd make a copy of the adata object here, so we don't have to change the original\n",
    "    # this would be in case we want to run it multiple times, perhaps the resolutions we put in didn't subset the clusters like we had hoped\n",
    "    # and we need to run multiple times to adjust the resolution slightly\n",
    "    \n",
    "    # this block is to figure out that there are two new subclusters and they should be named 8, 9\n",
    "    total_new_clusts = 0\n",
    "    old_clusts = sub_adatas.keys()\n",
    "    for sub_adata in sub_adatas:\n",
    "        total_new_clusts += sub_adatas[sub_adata].obs['leiden'].astype(int).unique().max() + 1\n",
    "    total_added_clusts = total_new_clusts - len(sub_adatas)\n",
    "    new_clust_names_start = max(adata.obs['leiden'].astype(int))+1\n",
    "    new_added_clust_names = [str(i) for i in range(new_clust_names_start,\n",
    "                                                   new_clust_names_start + total_added_clusts)]\n",
    "    \n",
    "    # this block is to build a new list of leiden clusters from the old one \n",
    "    new_leiden = list()\n",
    "    leiden_col = adata.obs['leiden'].copy()\n",
    "\n",
    "    # this builds the new leiden cluster list, now adding a .1, .2, etc. to each new cluster\n",
    "    for obs in leiden_col.index:\n",
    "        clust_name = leiden_col.loc[obs]\n",
    "        if clust_name not in old_clusts or sub_adatas[clust_name].obs.loc[obs, 'leiden'] == '0':\n",
    "            new_leiden.append(clust_name)\n",
    "        else:\n",
    "            new_leiden.append(clust_name + '.%s' % sub_adatas[clust_name].obs.loc[obs,'leiden'])\n",
    "\n",
    "    # this renames the .1, .2, etc clusters to the new, better names I came up with above (8 and 9)\n",
    "    new_leiden = pd.Series(new_leiden, index=adata.obs_names)\n",
    "    added_clusts = np.setdiff1d(new_leiden,adata.obs['leiden'])\n",
    "    new_leiden.replace(dict(zip(added_clusts, new_added_clust_names)), inplace=True)\n",
    "    \n",
    "    # replace the old leiden column, must do these steps sequentially \n",
    "    adata.obs['leiden'] = new_leiden.astype(int) # to order the clusters by number\n",
    "    adata.obs['leiden'] = new_leiden.astype(str) # to convert to string as normal\n",
    "#     adata.obs['leiden'] = new_leiden.astype('category') # don't do this, it messes things up, just let scanpy do it as it plots\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acg_nk = sub_cluster_mapper(acg_nk, sub_acg_nk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15,7))\n",
    "for color, ax, palette in zip(['batch', 'leiden'], ax, [None, sc.pl.palettes.default_20]):\n",
    "    ax.set_facecolor('whitesmoke')\n",
    "    sc.pl.umap(acg_nk,color=color, ax=ax, show=False, return_fig=False, size=30, palette=palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_raw(adata, transformed=True):\n",
    "    path = prefix + 'pkls/aggr/wells.sng.w_covars.pkl'\n",
    "    \n",
    "    with open(path,'rb') as file:\n",
    "        wells = pkl.load(file)\n",
    "    \n",
    "    for well in wells:\n",
    "        wells[well]['adata'].obs_names = [i[:16] + '-%s' % well for i in wells[well]['adata'].obs_names]\n",
    "    \n",
    "    raw = wells[0]['adata'].concatenate(*[wells[i]['adata'] for  i in range(1, 12)])[adata.obs_names,:]\n",
    "    \n",
    "    if transformed == True:\n",
    "        sc.pp.normalize_per_cell(raw,counts_per_cell_after=1e6)\n",
    "        sc.pp.log1p(raw)\n",
    "    \n",
    "    adata.raw = raw\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_raw(acg_nk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.verbosity = 0\n",
    "warnings.filterwarnings('ignore')\n",
    "sc.tl.rank_genes_groups(acg_nk, groupby='leiden', n_genes=100, use_raw=True)\n",
    "warnings.filterwarnings('default')\n",
    "sc.pl.rank_genes_groups(acg_nk, ncols=4, n_genes=20)\n",
    "sc.settings.verbosity = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
    "for color, ax, palette in zip(['cond', 'leiden'], ax, [None, sc.pl.palettes.default_20]):\n",
    "    sc.pl.umap(acg_nk,color=color, ax=ax, show=False, return_fig=False, size=20, palette=palette)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codec",
   "language": "python",
   "name": "codec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
