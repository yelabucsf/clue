{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CT Split\n",
    "\n",
    "Combining the ADT and mRNA results into one object, then splitting into 3 broad cell types for further processing.\n",
    "\n",
    "Originally, this just had the aggr projection, but I adjusted the code to also use Combat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import itertools as it\n",
    "import json\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.verbosity = 4\n",
    "sc.settings.set_figure_params(dpi=80)\n",
    "print(sc.__version__)\n",
    "sc.settings.n_jobs=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '/data/codec/production.run/mrna/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = prefix + 'pkls/aggr/wells.sng.w_covars.pkl'\n",
    "\n",
    "# with open(path,'wb') as file:\n",
    "#     pkl.dump(wells, file)\n",
    "    \n",
    "with open(path,'rb') as file:\n",
    "    wells = pkl.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Cell Barcodes, Filter\n",
    "\n",
    "I'm adjusting the cell barcodes to make them match their well number, which I also did with the ADTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for well in wells:\n",
    "    wells[well]['adata'].obs_names = [i[:16] + '-%s' % well for i in wells[well]['adata'].obs_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = wells[0]['adata'].concatenate(*[wells[i]['adata'] for  i in range(1, 12)]) # I really shouldn't do this, I should go back and run cellranger aggr, but for now just concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat.var['n_counts'] = concat.X.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Genes, Transform Data\n",
    "\n",
    "Drop genes with very low counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(concat.var['n_counts'].values, bins=np.logspace(np.log10(10),np.log10(2e5), 1000))\n",
    "plt.grid(False)\n",
    "plt.grid(True, 'both', 'both')\n",
    "plt.xscale('log')\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run On Separate Machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load in Data\n",
    "\n",
    "path = prefix + 'pkls/aggr/wells.sng.w_covars.pkl'\n",
    "    \n",
    "with open(path,'rb') as file:\n",
    "    wells = pkl.load(file)\n",
    "\n",
    "### Adjust Cell Barcodes, Filter\n",
    "\n",
    "# I'm adjusting the cell barcodes to make them match their well number, which I also did with the ADTs.\n",
    "\n",
    "for well in wells:\n",
    "    wells[well]['adata'].obs_names = [i[:16] + '-%s' % well for i in wells[well]['adata'].obs_names]\n",
    "\n",
    "### Concatenate\n",
    "\n",
    "concat = wells[0]['adata'].concatenate(*[wells[i]['adata'] for  i in range(1, 12)]) # I really shouldn't do this, I should go back and run cellranger aggr, but for now just concatenate\n",
    "\n",
    "concat.var['n_counts'] = concat.X.toarray().sum(axis=0)\n",
    "\n",
    "### Filter Genes, Transform Data\n",
    "\n",
    "# Drop genes with very low counts.\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.hist(concat.var['n_counts'].values, bins=np.logspace(np.log10(10),np.log10(2e5), 1000))\n",
    "# plt.grid(False)\n",
    "# plt.grid(True, 'both', 'both')\n",
    "# plt.xscale('log')\n",
    "# # plt.yscale('log')\n",
    "\n",
    "# remove any genes that are now empty\n",
    "sc.pp.filter_genes(concat, min_counts=100, inplace=True)\n",
    "\n",
    "sc.pp.normalize_per_cell(concat, counts_per_cell_after=1e6)\n",
    "\n",
    "sc.pp.log1p(concat)\n",
    "\n",
    "# ### Store Some Data\n",
    "\n",
    "# For posterity...\n",
    "\n",
    "# path = prefix + 'pkls/aggr/concat.norm.log.pkl'\n",
    "\n",
    "# # with open(path,'wb') as file:\n",
    "# #     pkl.dump(concat, file)\n",
    "    \n",
    "# with open(path,'rb') as file:\n",
    "#     concat = pkl.load(file)\n",
    "\n",
    "# path = prefix + 'obs/aggr/concat.obs.csv'\n",
    "# concat['adata'].obs.to_csv(path)\n",
    "\n",
    "# path = prefix + 'obs/aggr/concat.bcs.txt'\n",
    "\n",
    "# with open(path,'w') as file:\n",
    "#     for bc in concat['adata'].obs_names:\n",
    "#         file.write(bc + '\\n')\n",
    "\n",
    "sc.pp.scale(concat)\n",
    "sc.pp.combat(concat, key='batch',covariates=['cond','free_id'])\n",
    "sc.pp.scale(concat)\n",
    "sc.pp.pca(concat, n_comps=200)\n",
    "\n",
    "path = prefix + 'pkls/aggr/ct.split.pkl'\n",
    "\n",
    "with open(path,'wb') as file:\n",
    "    pkl.dump(concat, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = prefix + 'pkls/aggr/ct.split.pkl'\n",
    "    \n",
    "with open(path,'rb') as file:\n",
    "    concat = pkl.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original code I ran on a separate machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ### Dimensionality Reduction, Visualization and Clustering\n",
    "\n",
    "# Perform on a separate, more powerful machine.\n",
    "\n",
    "# # import scanpy as sc\n",
    "# # import pickle as pkl\n",
    "# # import warnings\n",
    "# # warnings.filterwarnings('ignore')\n",
    "\n",
    "# # path = '/data/codec/production.run/mrna/pkls/aggr/concat.norm.log.pkl'\n",
    "# # with open(path,'rb') as file:\n",
    "# #     concat = pkl.load(file)\n",
    "\n",
    "# # concat['unscaled'] = concat['adata'].copy()\n",
    "# # sc.pp.scale(concat['adata'])\n",
    "# # sc.settings.verbosity = 4\n",
    "# # sc.settings.n_jobs=30\n",
    "# # sc.pp.combat(concat['adata'], key='batch',covariates=['cond','free_id'])\n",
    "# # sc.pp.pca(concat['adata'],n_comps=200)\n",
    "# # sc.pp.neighbors(concat['adata'],n_neighbors=15,n_pcs=100)\n",
    "# # sc.tl.umap(concat['adata'])\n",
    "\n",
    "# # path = '/data/codec/production.run/mrna/pkls/aggr/concat.aggr.combat.dimred.pkl'\n",
    "# # warnings.filterwarnings('default')\n",
    "# # with open(path,'wb') as file:\n",
    "# #     pkl.dump(concat, file, protocol=4)\n",
    "\n",
    "# path = prefix + 'pkls/aggr/concat.aggr.combat.dimred.pkl'\n",
    "\n",
    "# with open(path,'rb') as file:\n",
    "#     concat = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca_variance_ratio(concat, log=True, n_pcs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "sc.pp.neighbors(concat, n_neighbors=15, n_pcs=150)\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.umap(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(concat, resolution=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
    "for color, ax in zip(['cond', 'leiden'], ax):\n",
    "    sc.pl.umap(concat,color=color, ax=ax, show=False, return_fig=False, size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(concat, resolution=0.3, restrict_to=('leiden',['24']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
    "for color, ax in zip(['cond', 'leiden'], ax):\n",
    "    sc.pl.umap(concat,color=color, ax=ax, show=False, return_fig=False, size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(concat, resolution=0.3, restrict_to=('leiden',['24,1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
    "for color, ax in zip(['cond', 'leiden'], ax):\n",
    "    sc.pl.umap(concat,color=color, ax=ax, show=False, return_fig=False, size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.verbosity = 0\n",
    "warnings.filterwarnings('ignore')\n",
    "sc.tl.rank_genes_groups(concat, groupby='leiden', n_genes=100, groups=['24,1,2'])\n",
    "warnings.filterwarnings('default')\n",
    "sc.pl.rank_genes_groups(concat, ncols=5, n_genes=20)\n",
    "sc.settings.verbosity = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Gene Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ['SOX4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "ax.set_facecolor('black')\n",
    "sc.pl.umap(acg_t, color=f, ax=ax,show=False, return_fig=False, size=5, use_raw=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
    "for color, ax in zip(['percent_mito', 'n_counts'], ax):\n",
    "    sc.pl.umap(concat, color=color, ax=ax, show=False, return_fig=False, size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = concat.obs['batch'].unique() # get a list of the batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new column in the `.obs` for each batch that is of dtype `int` and that just takes on values of 0 and 1 so that it gets plotted as a continuous variable instead of a categorical one\n",
    "for batch in batches:\n",
    "    concat.obs['batch_%s' % batch] = (concat.obs['batch'] == batch).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot now with sort_order=True, which should apply to this new continuous variable\n",
    "sc.pl.umap(concat, color=['batch_%s' % i for i in batches],sort_order=True, ncols=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(concat, color=['APAF1','BAK1','BAX','FAS','TNFRSF10B','TNFRSF10A','ANXA5','TP53', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = '12'\n",
    "concat['adata'].obs['val'] = concat['adata'].obs['leiden'] == val\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_facecolor('gray')\n",
    "sc.pl.umap(concat['adata'],color='val', ax=ax)\n",
    "concat['adata'].obs.drop(columns='val', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_adatas = dict() # put the new subsetted adata objects in a dictionary of adatas\n",
    "sub_adatas['12'] = concat['adata'][concat['adata'].obs['leiden'] == '12'].copy()\n",
    "sub_adatas['22'] = concat['adata'][concat['adata'].obs['leiden'] == '22'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(sub_adatas['12'], resolution=0.5) # subcluster them using Leiden\n",
    "sc.pl.umap(sub_adatas['12'], color='leiden', size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupings = [[0, 1, 3, 4, 5, 6, 7],\n",
    "             [2],\n",
    "             ]\n",
    "grouped_clusts = [i for j in groupings for i in j]\n",
    "numclusts = np.unique(sub_adatas['12'].obs['leiden'].values.astype(int))\n",
    "for i in np.setdiff1d(numclusts, grouped_clusts):\n",
    "    groupings.append([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctdict = dict()\n",
    "for i in range(len(groupings)):\n",
    "    ctdict['ct%s' % str(i)] = groupings[i]\n",
    "\n",
    "sub_adatas['12'].obs['celltype'] = sub_adatas['12'].obs['leiden']\n",
    "for ct in ctdict:\n",
    "    for clust in ctdict[ct]:\n",
    "        sub_adatas['12'].obs['celltype'].replace(str(clust), ct, regex=True, inplace=True)\n",
    "sub_adatas['12'].obs['leiden'] = [i.strip('ct') for i in sub_adatas['12'].obs['celltype'].astype('category')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(sub_adatas['12'], color='leiden', size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(sub_adatas['22'], resolution=0.1) # subcluster them using Leiden\n",
    "sc.pl.umap(sub_adatas['22'], color='leiden', size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map them back to the clusters on the original adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_cluster_mapper(adata, sub_adatas):\n",
    "    '''\n",
    "    This takes in the adata object and inserts a new leiden column in the `.obs`. \n",
    "    \n",
    "    This function is really convoluted and there's probably a better, simpler way to do it,\n",
    "    but it should theoretically work for any number of subclusters\n",
    "    '''\n",
    "    # ideally you'd make a copy of the adata object here, so we don't have to change the original\n",
    "    # this would be in case we want to run it multiple times, perhaps the resolutions we put in didn't subset the clusters like we had hoped\n",
    "    # and we need to run multiple times to adjust the resolution slightly\n",
    "    \n",
    "    # this block is to figure out that there are two new subclusters and they should be named 8, 9\n",
    "    total_new_clusts = 0\n",
    "    old_clusts = sub_adatas.keys()\n",
    "    for sub_adata in sub_adatas:\n",
    "        total_new_clusts += sub_adatas[sub_adata].obs['leiden'].astype(int).unique().max() + 1\n",
    "    total_added_clusts = total_new_clusts - len(sub_adatas)\n",
    "    new_clust_names_start = max(adata.obs['leiden'].astype(int))+1\n",
    "    new_added_clust_names = [str(i) for i in range(new_clust_names_start,\n",
    "                                                   new_clust_names_start + total_added_clusts)]\n",
    "    \n",
    "    # this block is to build a new list of leiden clusters from the old one \n",
    "    new_leiden = list()\n",
    "    leiden_col = adata.obs['leiden'].copy()\n",
    "\n",
    "    # this builds the new leiden cluster list, now adding a .1, .2, etc. to each new cluster\n",
    "    for obs in leiden_col.index:\n",
    "        clust_name = leiden_col.loc[obs]\n",
    "        if clust_name not in old_clusts or sub_adatas[clust_name].obs.loc[obs, 'leiden'] == '0':\n",
    "            new_leiden.append(clust_name)\n",
    "        else:\n",
    "            new_leiden.append(clust_name + '.%s' % sub_adatas[clust_name].obs.loc[obs,'leiden'])\n",
    "\n",
    "    # this renames the .1, .2, etc clusters to the new, better names I came up with above (8 and 9)\n",
    "    new_leiden = pd.Series(new_leiden, index=adata.obs_names)\n",
    "    added_clusts = np.setdiff1d(new_leiden,adata.obs['leiden'])\n",
    "    new_leiden.replace(dict(zip(added_clusts, new_added_clust_names)), inplace=True)\n",
    "    \n",
    "    # replace the old leiden column, must do these steps sequentially \n",
    "    adata.obs['leiden'] = new_leiden.astype(int) # to order the clusters by number\n",
    "    adata.obs['leiden'] = new_leiden.astype(str) # to convert to string as normal\n",
    "#     adata.obs['leiden'] = new_leiden.astype('category') # don't do this, it messes things up, just let scanpy do it as it plots\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat['adata'] = sub_cluster_mapper(concat['adata'], sub_adatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
    "for color, ax in zip(['percent_mito', 'leiden'], ax):\n",
    "    sc.pl.umap(concat['adata'],color=color, ax=ax, show=False, return_fig=False, size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(20,4))\n",
    "sns.violinplot(data=concat['adata'].obs[['leiden','percent_mito']], x='leiden',y='percent_mito', ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_clusts = [2, 11, 13, 18, 19, 22, 24]\n",
    "keep_clusts = np.setdiff1d(range(31), remove_clusts).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cells = list()\n",
    "for i in tqdm(concat['adata'].obs_names):\n",
    "    if concat['adata'].obs.loc[i,'leiden'] in keep_clusts:\n",
    "        keep_cells.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = prefix + 'obs/aggr/keep.bcs.txt'\n",
    "\n",
    "# with open(path,'w') as file:\n",
    "#     for bc in keep_cells:\n",
    "#         file.write(bc + '\\n')\n",
    "        \n",
    "with open(path,'r') as file:\n",
    "    keep_cells = [i.strip() for i in file.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ran on separate machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scanpy as sc\n",
    "# import pickle as pkl\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# sc.settings.verbosity = 4\n",
    "# sc.settings.n_jobs=30\n",
    "\n",
    "# path = '/data/codec/production.run/mrna/pkls/aggr/concat.norm.log.pkl'\n",
    "# with open(path,'rb') as file:\n",
    "#     concat = pkl.load(file)\n",
    "\n",
    "# path = '/data/codec/production.run/mrna/obs/aggr/keep.bcs.txt'\n",
    "\n",
    "# with open(path,'r') as file:\n",
    "#     keep_cells = [i.strip() for i in file.readlines()]\n",
    "\n",
    "\n",
    "# concat['adata'] = concat['adata'][keep_cells,:].copy()\n",
    "\n",
    "# sc.pp.scale(concat['adata'])\n",
    "# sc.pp.combat(concat['adata'], key='batch',covariates=['cond','free_id'])\n",
    "# sc.pp.pca(concat['adata'],n_comps=200)\n",
    "# sc.pp.neighbors(concat['adata'],n_neighbors=15,n_pcs=100)\n",
    "# sc.tl.umap(concat['adata'])\n",
    "\n",
    "# path = '/data/codec/production.run/mrna/pkls/aggr/concat.nomito.pkl'\n",
    "# warnings.filterwarnings('default')\n",
    "# with open(path,'wb') as file:\n",
    "#     pkl.dump(concat, file, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = prefix + 'pkls/aggr/concat.nomito.pkl'\n",
    "    \n",
    "with open(path,'rb') as file:\n",
    "    concat = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca_variance_ratio(concat['adata'],log=True, n_pcs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(concat['adata'], resolution=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
    "for color, ax in zip(['cond', 'leiden'], ax):\n",
    "    sc.pl.umap(concat['adata'],color=color, ax=ax, show=False, return_fig=False, size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_adatas = dict() # put the new subsetted adata objects in a dictionary of adatas\n",
    "sub_adatas['14'] = concat['adata'][concat['adata'].obs['leiden'] == '14'].copy()\n",
    "sub_adatas['15'] = concat['adata'][concat['adata'].obs['leiden'] == '15'].copy()\n",
    "sub_adatas['20'] = concat['adata'][concat['adata'].obs['leiden'] == '20'].copy()\n",
    "sub_adatas['22'] = concat['adata'][concat['adata'].obs['leiden'] == '22'].copy()\n",
    "sub_adatas['24'] = concat['adata'][concat['adata'].obs['leiden'] == '24'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(sub_adatas['14'], resolution=0.3) # subcluster them using Leiden\n",
    "sc.pl.umap(sub_adatas['14'], color='leiden', size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupings = [[0, 1, 2],\n",
    "             ]\n",
    "grouped_clusts = [i for j in groupings for i in j]\n",
    "numclusts = np.unique(sub_adatas['14'].obs['leiden'].values.astype(int))\n",
    "for i in np.setdiff1d(numclusts, grouped_clusts):\n",
    "    groupings.append([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctdict = dict()\n",
    "for i in range(len(groupings)):\n",
    "    ctdict['ct%s' % str(i)] = groupings[i]\n",
    "\n",
    "sub_adatas['14'].obs['celltype'] = sub_adatas['14'].obs['leiden']\n",
    "for ct in ctdict:\n",
    "    for clust in ctdict[ct]:\n",
    "        sub_adatas['14'].obs['celltype'].replace(str(clust), ct, regex=True, inplace=True)\n",
    "sub_adatas['14'].obs['leiden'] = [i.strip('ct') for i in sub_adatas['14'].obs['celltype'].astype('category')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(sub_adatas['14'], color='leiden', size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(sub_adatas['15'], resolution=0.1) # subcluster them using Leiden\n",
    "sc.pl.umap(sub_adatas['15'], color='leiden', size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(sub_adatas['20'], resolution=1) # subcluster them using Leiden\n",
    "sc.pl.umap(sub_adatas['20'], color='leiden', size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupings = [[2, 4, 6, 7],\n",
    "             ]\n",
    "grouped_clusts = [i for j in groupings for i in j]\n",
    "numclusts = np.unique(sub_adatas['20'].obs['leiden'].values.astype(int))\n",
    "for i in np.setdiff1d(numclusts, grouped_clusts):\n",
    "    groupings.append([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctdict = dict()\n",
    "for i in range(len(groupings)):\n",
    "    ctdict['ct%s' % str(i)] = groupings[i]\n",
    "\n",
    "sub_adatas['20'].obs['celltype'] = sub_adatas['20'].obs['leiden']\n",
    "for ct in ctdict:\n",
    "    for clust in ctdict[ct]:\n",
    "        sub_adatas['20'].obs['celltype'].replace(str(clust), ct, regex=True, inplace=True)\n",
    "sub_adatas['20'].obs['leiden'] = [i.strip('ct') for i in sub_adatas['20'].obs['celltype'].astype('category')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(sub_adatas['20'], color='leiden', size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.verbosity = 0 \n",
    "warnings.filterwarnings('ignore')\n",
    "sc.tl.rank_genes_groups(sub_adatas['20'], groupby='leiden', n_genes=50)\n",
    "warnings.filterwarnings('default')\n",
    "sc.pl.rank_genes_groups(sub_adatas['20'], ncols=5, n_genes=20)\n",
    "sc.settings.verbosity = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(sub_adatas['20'], color=['cond'], size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(sub_adatas['22'], resolution=0.001) # subcluster them using Leiden\n",
    "sc.pl.umap(sub_adatas['22'], color=['leiden', 'cond'], size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(sub_adatas['24'], resolution=0.3) # subcluster them using Leiden\n",
    "sc.pl.umap(sub_adatas['24'], color='leiden', size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(sub_adatas['24'], color='cond', size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.verbosity = 0 \n",
    "warnings.filterwarnings('ignore')\n",
    "sc.tl.rank_genes_groups(sub_adatas['24'], groupby='leiden', n_genes=20)\n",
    "warnings.filterwarnings('default')\n",
    "sc.pl.rank_genes_groups(sub_adatas['24'], ncols=5, n_genes=20)\n",
    "sc.settings.verbosity = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map them back to the clusters on the original adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_cluster_mapper(adata, sub_adatas):\n",
    "    '''\n",
    "    This takes in the adata object and inserts a new leiden column in the `.obs`. \n",
    "    \n",
    "    This function is really convoluted and there's probably a better, simpler way to do it,\n",
    "    but it should theoretically work for any number of subclusters\n",
    "    '''\n",
    "    # ideally you'd make a copy of the adata object here, so we don't have to change the original\n",
    "    # this would be in case we want to run it multiple times, perhaps the resolutions we put in didn't subset the clusters like we had hoped\n",
    "    # and we need to run multiple times to adjust the resolution slightly\n",
    "    \n",
    "    # this block is to figure out that there are two new subclusters and they should be named 8, 9\n",
    "    total_new_clusts = 0\n",
    "    old_clusts = sub_adatas.keys()\n",
    "    for sub_adata in sub_adatas:\n",
    "        total_new_clusts += sub_adatas[sub_adata].obs['leiden'].astype(int).unique().max() + 1\n",
    "    total_added_clusts = total_new_clusts - len(sub_adatas)\n",
    "    new_clust_names_start = max(adata.obs['leiden'].astype(int))+1\n",
    "    new_added_clust_names = [str(i) for i in range(new_clust_names_start,\n",
    "                                                   new_clust_names_start + total_added_clusts)]\n",
    "    \n",
    "    # this block is to build a new list of leiden clusters from the old one \n",
    "    new_leiden = list()\n",
    "    leiden_col = adata.obs['leiden'].copy()\n",
    "\n",
    "    # this builds the new leiden cluster list, now adding a .1, .2, etc. to each new cluster\n",
    "    for obs in leiden_col.index:\n",
    "        clust_name = leiden_col.loc[obs]\n",
    "        if clust_name not in old_clusts or sub_adatas[clust_name].obs.loc[obs, 'leiden'] == '0':\n",
    "            new_leiden.append(clust_name)\n",
    "        else:\n",
    "            new_leiden.append(clust_name + '.%s' % sub_adatas[clust_name].obs.loc[obs,'leiden'])\n",
    "\n",
    "    # this renames the .1, .2, etc clusters to the new, better names I came up with above (8 and 9)\n",
    "    new_leiden = pd.Series(new_leiden, index=adata.obs_names)\n",
    "    added_clusts = np.setdiff1d(new_leiden,adata.obs['leiden'])\n",
    "    new_leiden.replace(dict(zip(added_clusts, new_added_clust_names)), inplace=True)\n",
    "    \n",
    "    # replace the old leiden column, must do these steps sequentially \n",
    "    adata.obs['leiden'] = new_leiden.astype(int) # to order the clusters by number\n",
    "    adata.obs['leiden'] = new_leiden.astype(str) # to convert to string as normal\n",
    "#     adata.obs['leiden'] = new_leiden.astype('category') # don't do this, it messes things up, just let scanpy do it as it plots\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat['adata'] = sub_cluster_mapper(concat['adata'], sub_adatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
    "for color, ax in zip(['free_id', 'batch'], ax):\n",
    "    sc.pl.umap(concat['adata'],color=color, ax=ax, show=False, return_fig=False, size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "sc.pl.umap(concat['adata'], color='leiden', ax=ax, show=False, return_fig=False, size=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_tnk = [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 16, 19]\n",
    "ct_b = [9, 12, 18]\n",
    "ct_m = [7, 14, 15, 17]\n",
    "ct_other = [22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]\n",
    "ct_drop = [13, 20, 21, 26, 27]\n",
    "        \n",
    "cts = ['tnk', 'b', 'm', 'other', 'drop']\n",
    "\n",
    "ctdict = dict()\n",
    "ctdict['tnk'] = ct_tnk\n",
    "ctdict['b'] = ct_b\n",
    "ctdict['m'] = ct_m\n",
    "ctdict['other'] = ct_other\n",
    "ctdict['drop'] = ct_drop\n",
    "concat['adata'].obs['ct1'] = concat['adata'].obs['leiden']\n",
    "for ct in ctdict:\n",
    "    for clust in ctdict[ct]:\n",
    "        concat['adata'].obs['ct1'].replace(str(clust), ct, inplace=True)\n",
    "concat['adata'].obs['ct1'] = concat['adata'].obs['ct1'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "sc.pl.umap(concat['adata'], color='ct1', ax=ax, show=False, return_fig=False, size=2, palette=sc.pl.palettes.default_20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. Because I couldn't export here, I ran on a separate machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scanpy as sc\n",
    "# import pickle as pkl\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# sc.settings.verbosity = 4\n",
    "# sc.settings.n_jobs=30\n",
    "\n",
    "# path = '/data/codec/production.run/mrna/pkls/aggr/concat.nomito.pkl'\n",
    "\n",
    "# with open(path,'rb') as file:\n",
    "#     concat = pkl.load(file)\n",
    "\n",
    "# path = '/data/codec/production.run/adts/pkls/combat/concat.combat.adts.norm.log.pkl'\n",
    "\n",
    "# with open(path,'rb') as file:\n",
    "#     concat_adts = pkl.load(file)\n",
    "\n",
    "# transcripts = concat['adata'].var_names\n",
    "# proteins = concat_adts['adata'].var_names\n",
    "\n",
    "# adts_df = pd.DataFrame(concat_adts['adata'].X, columns=proteins, index=concat_adts['adata'].obs_names)\n",
    "\n",
    "# concat['adata'].obs = concat['adata'].obs.join(adts_df)\n",
    "\n",
    "# sc.tl.leiden(concat['adata'], resolution=0.8)\n",
    "\n",
    "# sub_adatas = dict() # put the new subsetted adata objects in a dictionary of adatas\n",
    "# sub_adatas['14'] = concat['adata'][concat['adata'].obs['leiden'] == '14'].copy()\n",
    "# sub_adatas['15'] = concat['adata'][concat['adata'].obs['leiden'] == '15'].copy()\n",
    "# sub_adatas['20'] = concat['adata'][concat['adata'].obs['leiden'] == '20'].copy()\n",
    "# sub_adatas['22'] = concat['adata'][concat['adata'].obs['leiden'] == '22'].copy()\n",
    "# sub_adatas['24'] = concat['adata'][concat['adata'].obs['leiden'] == '24'].copy()\n",
    "\n",
    "# sc.tl.leiden(sub_adatas['14'], resolution=0.3) # subcluster them using Leiden\n",
    "\n",
    "# groupings = [[0, 1, 2],\n",
    "#              ]\n",
    "# grouped_clusts = [i for j in groupings for i in j]\n",
    "# numclusts = np.unique(sub_adatas['14'].obs['leiden'].values.astype(int))\n",
    "# for i in np.setdiff1d(numclusts, grouped_clusts):\n",
    "#     groupings.append([i])\n",
    "\n",
    "# ctdict = dict()\n",
    "# for i in range(len(groupings)):\n",
    "#     ctdict['ct%s' % str(i)] = groupings[i]\n",
    "\n",
    "# sub_adatas['14'].obs['celltype'] = sub_adatas['14'].obs['leiden']\n",
    "# for ct in ctdict:\n",
    "#     for clust in ctdict[ct]:\n",
    "#         sub_adatas['14'].obs['celltype'].replace(str(clust), ct, regex=True, inplace=True)\n",
    "# sub_adatas['14'].obs['leiden'] = [i.strip('ct') for i in sub_adatas['14'].obs['celltype'].astype('category')]\n",
    "\n",
    "# sc.tl.leiden(sub_adatas['15'], resolution=0.1) # subcluster them using Leiden\n",
    "\n",
    "# sc.tl.leiden(sub_adatas['20'], resolution=1) # subcluster them using Leiden\n",
    "\n",
    "# groupings = [[2, 4, 6, 7],\n",
    "#              ]\n",
    "# grouped_clusts = [i for j in groupings for i in j]\n",
    "# numclusts = np.unique(sub_adatas['20'].obs['leiden'].values.astype(int))\n",
    "# for i in np.setdiff1d(numclusts, grouped_clusts):\n",
    "#     groupings.append([i])\n",
    "\n",
    "# ctdict = dict()\n",
    "# for i in range(len(groupings)):\n",
    "#     ctdict['ct%s' % str(i)] = groupings[i]\n",
    "\n",
    "# sub_adatas['20'].obs['celltype'] = sub_adatas['20'].obs['leiden']\n",
    "# for ct in ctdict:\n",
    "#     for clust in ctdict[ct]:\n",
    "#         sub_adatas['20'].obs['celltype'].replace(str(clust), ct, regex=True, inplace=True)\n",
    "# sub_adatas['20'].obs['leiden'] = [i.strip('ct') for i in sub_adatas['20'].obs['celltype'].astype('category')]\n",
    "\n",
    "# sc.tl.leiden(sub_adatas['22'], resolution=0.001) # subcluster them using Leiden\n",
    "\n",
    "# sc.tl.leiden(sub_adatas['24'], resolution=0.3) # subcluster them using Leiden\n",
    "\n",
    "# def sub_cluster_mapper(adata, sub_adatas):\n",
    "#     '''\n",
    "#     This takes in the adata object and inserts a new leiden column in the `.obs`.\n",
    "\n",
    "#     This function is really convoluted and there's probably a better, simpler way to do it,\n",
    "#     but it should theoretically work for any number of subclusters\n",
    "#     '''\n",
    "#     # ideally you'd make a copy of the adata object here, so we don't have to change the original\n",
    "#     # this would be in case we want to run it multiple times, perhaps the resolutions we put in didn't subset the clusters like we had hoped\n",
    "#     # and we need to run multiple times to adjust the resolution slightly\n",
    "\n",
    "#     # this block is to figure out that there are two new subclusters and they should be named 8, 9\n",
    "#     total_new_clusts = 0\n",
    "#     old_clusts = sub_adatas.keys()\n",
    "#     for sub_adata in sub_adatas:\n",
    "#         total_new_clusts += sub_adatas[sub_adata].obs['leiden'].astype(int).unique().max() + 1\n",
    "#     total_added_clusts = total_new_clusts - len(sub_adatas)\n",
    "#     new_clust_names_start = max(adata.obs['leiden'].astype(int))+1\n",
    "#     new_added_clust_names = [str(i) for i in range(new_clust_names_start,\n",
    "#                                                    new_clust_names_start + total_added_clusts)]\n",
    "\n",
    "#     # this block is to build a new list of leiden clusters from the old one\n",
    "#     new_leiden = list()\n",
    "#     leiden_col = adata.obs['leiden'].copy()\n",
    "\n",
    "#     # this builds the new leiden cluster list, now adding a .1, .2, etc. to each new cluster\n",
    "#     for obs in leiden_col.index:\n",
    "#         clust_name = leiden_col.loc[obs]\n",
    "#         if clust_name not in old_clusts or sub_adatas[clust_name].obs.loc[obs, 'leiden'] == '0':\n",
    "#             new_leiden.append(clust_name)\n",
    "#         else:\n",
    "#             new_leiden.append(clust_name + '.%s' % sub_adatas[clust_name].obs.loc[obs,'leiden'])\n",
    "\n",
    "#     # this renames the .1, .2, etc clusters to the new, better names I came up with above (8 and 9)\n",
    "#     new_leiden = pd.Series(new_leiden, index=adata.obs_names)\n",
    "#     added_clusts = np.setdiff1d(new_leiden,adata.obs['leiden'])\n",
    "#     new_leiden.replace(dict(zip(added_clusts, new_added_clust_names)), inplace=True)\n",
    "\n",
    "#     # replace the old leiden column, must do these steps sequentially\n",
    "#     adata.obs['leiden'] = new_leiden.astype(int) # to order the clusters by number\n",
    "#     adata.obs['leiden'] = new_leiden.astype(str) # to convert to string as normal\n",
    "# #     adata.obs['leiden'] = new_leiden.astype('category') # don't do this, it messes things up, just let scanpy do it as it plots\n",
    "#     return adata\n",
    "\n",
    "# concat['adata'] = sub_cluster_mapper(concat['adata'], sub_adatas)\n",
    "\n",
    "# ct_tnk = [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 16, 19]\n",
    "# ct_b = [9, 12, 18]\n",
    "# ct_m = [7, 14, 15, 17]\n",
    "# ct_other = [22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]\n",
    "# ct_drop = [13, 20, 21, 26, 27]\n",
    "\n",
    "# cts = ['tnk', 'b', 'm', 'other', 'drop']\n",
    "\n",
    "# ctdict = dict()\n",
    "# ctdict['tnk'] = ct_tnk\n",
    "# ctdict['b'] = ct_b\n",
    "# ctdict['m'] = ct_m\n",
    "# ctdict['other'] = ct_other\n",
    "# ctdict['drop'] = ct_drop\n",
    "# concat['adata'].obs['ct1'] = concat['adata'].obs['leiden']\n",
    "# for ct in ctdict:\n",
    "#     for clust in ctdict[ct]:\n",
    "#         concat['adata'].obs['ct1'].replace(str(clust), ct, inplace=True)\n",
    "# concat['adata'].obs['ct1'] = concat['adata'].obs['ct1'].astype('category')\n",
    "\n",
    "# for ct in cts:\n",
    "#     ct_dict = dict()\n",
    "#     ct_dict['adata'] = concat['adata'][concat['adata'].obs['ct1'] == ct].copy()\n",
    "\n",
    "#     path = '/data/codec/production.run/mrna/pkls/aggr/%s.pkl' % ct\n",
    "\n",
    "#     with open(path,'wb') as file:\n",
    "#                 pkl.dump(ct_dict, file, protocol=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codec",
   "language": "python",
   "name": "codec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
